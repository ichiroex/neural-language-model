loading training data...
txt/bb.train.txt
dataset size 28000
symbol vocab size: 3552
symbol vocab size(actual): 3549

epoch: 0 / 30
ソフトバンク [[  1.41636819e-01   1.13461137e+00  -9.76119101e-01   1.19326258e+00
   -4.80736852e-01   8.29168916e-01  -7.98190176e-01  -4.69589531e-01
    7.75329292e-01   2.81531191e+00   1.39948857e+00   7.81078488e-02
   -1.64702129e+00   4.77236181e-01  -9.40600872e-01  -8.61139894e-01
    1.36778820e+00   1.23467362e+00   1.76595891e+00   1.53962597e-01
    3.85070086e-01   1.52330780e+00   6.78732276e-01  -2.10785961e+00
   -6.78741515e-01   4.25647385e-02  -9.00218248e-01  -1.85426164e+00
   -8.50679040e-01   1.78909528e+00  -5.15486062e-01  -3.79733235e-01
    3.79388593e-02  -1.19978201e+00  -1.37383723e+00   2.60392857e+00
   -1.07333448e-03  -3.46731603e-01  -9.45308268e-01   2.72696644e-01
   -8.10346961e-01   6.59307599e-01   1.20530911e-02  -8.38838637e-01
    3.40018392e-01  -8.96505237e-01   1.82404804e+00   1.75947523e+00
    8.02327871e-01   2.36315548e-01   1.75355166e-01  -6.06159046e-02
    2.58229804e+00  -3.32623690e-01   9.47894096e-01   3.03522646e-01
    1.54333159e-01  -8.82467031e-02   1.27663279e+00  -1.24547116e-01
    3.47027779e-01  -4.39781398e-02   1.84969771e+00  -7.97553395e-04
    1.60512733e+00  -8.31969976e-01  -1.67651916e+00   4.60507721e-02
    1.44036174e-01  -1.19872546e+00  -4.13549989e-01  -7.15817511e-01
    3.72662067e-01   1.86055565e+00   4.42894608e-01   8.25650752e-01
   -1.43436742e+00   1.54185951e-01   8.27509642e-01   8.03829789e-01
    2.85060614e-01  -9.38408077e-01  -4.16020304e-01   7.52868712e-01
    1.67543066e+00  -5.78905106e-01   1.26792610e+00  -1.60035753e+00
    2.11052656e+00  -2.34789744e-01  -5.27006269e-01   1.95850468e+00
   -3.46223712e-01   3.85071456e-01  -3.00550014e-01   7.73027003e-01
    8.29788029e-01  -5.73644698e-01  -1.25050187e+00  -1.85564920e-01]]
train mean loss=121.200882503
training perplexity=20.6976892287
saving model....
epoch: 1 / 30
ソフトバンク [[ 0.16000341  1.14697003 -0.99591333  1.19270933 -0.48392504  0.8485899
  -0.81927949 -0.45267791  0.75360292  2.81123734  1.38643801  0.08419111
  -1.66967428  0.49579114 -0.92240942 -0.83843386  1.34294951  1.23486626
   1.7450366   0.15952893  0.38414177  1.5121721   0.65770549 -2.12719607
  -0.65844804  0.06331258 -0.89639491 -1.87565136 -0.85604972  1.77023077
  -0.53489804 -0.39120045  0.01883711 -1.17931867 -1.392874    2.62323475
  -0.01863323 -0.32550931 -0.93297726  0.25434479 -0.79267997  0.67846769
   0.02879795 -0.8468821   0.32826668 -0.91633624  1.80563426  1.74264061
   0.81222278  0.21936482  0.15628318 -0.07763933  2.56458187 -0.35094428
   0.92929721  0.29162708  0.13489856 -0.10993144  1.29143786 -0.14138702
   0.32654828 -0.06157833  1.84968686 -0.01879542  1.58294785 -0.83039033
  -1.69692171  0.02768268  0.12819539 -1.17725909 -0.43092439 -0.71269172
   0.39368945  1.83837843  0.42907044  0.84010535 -1.45481026  0.1683445
   0.84154767  0.79325587  0.30267555 -0.92024678 -0.39852723  0.75864595
   1.69497395 -0.5984357   1.27112389 -1.62452734  2.09024835 -0.25237924
  -0.50767386  1.97301292 -0.32512271  0.36451927 -0.27985722  0.79454869
   0.80702227 -0.55604708 -1.2707479  -0.2070522 ]]
train mean loss=84.1052321625
training perplexity=8.1876817899
saving model....
epoch: 2 / 30
ソフトバンク [[ 0.16773108  1.15369749 -1.00693059  1.19598258 -0.49526307  0.85899442
  -0.83037794 -0.44291523  0.74045694  2.81209946  1.38368869  0.09014647
  -1.6830771   0.50618613 -0.91192591 -0.82414848  1.3280493   1.24179733
   1.73432398  0.1519395   0.39016488  1.50775695  0.64708942 -2.13948894
  -0.64743465  0.075036   -0.89623338 -1.88731468 -0.86604208  1.75402534
  -0.54566741 -0.39590061  0.00559008 -1.16892099 -1.40484929  2.63513422
  -0.03210156 -0.31374326 -0.92410421  0.24440558 -0.78140825  0.68996209
   0.03790704 -0.852314    0.32701886 -0.9282431   1.79492188  1.7338475
   0.81761783  0.20843743  0.14642608 -0.08592291  2.55645609 -0.36279002
   0.92115426  0.28535178  0.12294672 -0.12314742  1.30079412 -0.14937229
   0.31451222 -0.06873944  1.85443866 -0.03098928  1.5700233  -0.82470113
  -1.70960176  0.01861914  0.12205726 -1.16373396 -0.438263   -0.70669019
   0.40740216  1.82699656  0.42074472  0.84444517 -1.46761715  0.17271794
   0.84715754  0.79303473  0.31049755 -0.91196841 -0.38876656  0.75837231
   1.70370257 -0.61400974  1.27900994 -1.64005518  2.08128357 -0.26365674
  -0.49837801  1.9760735  -0.3128998   0.35222155 -0.26847413  0.80728924
   0.79129714 -0.54714847 -1.28194726 -0.22022755]]
train mean loss=75.953432094
training perplexity=6.67811526881
saving model....
epoch: 3 / 30
ソフトバンク [[ 0.17112882  1.15908885 -1.01425433  1.19890153 -0.50593728  0.86601985
  -0.83719373 -0.43550178  0.7313568   2.81401086  1.38383138  0.09408209
  -1.69209445  0.51329929 -0.90476435 -0.81396616  1.31772089  1.24958003
   1.72773361  0.14305817  0.39597276  1.50638902  0.64046377 -2.1489985
  -0.64013433  0.08328381 -0.89637852 -1.89516509 -0.87501276  1.74182701
  -0.5530389  -0.39773706 -0.00462759 -1.16257536 -1.41335917  2.64347553
  -0.04279616 -0.30574176 -0.91826952  0.23796597 -0.7733081   0.69821763
   0.04409089 -0.85681498  0.32911611 -0.93670171  1.78741276  1.72753119
   0.81960964  0.20032077  0.14041045 -0.08980773  2.55169868 -0.37152421
   0.91700011  0.28242698  0.11421046 -0.13255836  1.30666351 -0.15413627
   0.30612794 -0.07182875  1.85859716 -0.04006313  1.56124866 -0.82011968
  -1.71878445  0.01303938  0.11945645 -1.15371943 -0.4419207  -0.70146507
   0.41763103  1.81960487  0.41439953  0.84470528 -1.47707915  0.17381012
   0.84949994  0.79669064  0.31458345 -0.90685838 -0.38181236  0.75780106
   1.70847881 -0.62618381  1.28553355 -1.65126812  2.07658982 -0.2722773
  -0.49317279  1.97513247 -0.30445173  0.34353548 -0.26117268  0.81632435
   0.77958864 -0.54152811 -1.2896595  -0.22969528]]
train mean loss=72.0784934289
training perplexity=6.06153055924
saving model....
epoch: 4 / 30
ソフトバンク [[ 0.17261274  1.16347921 -1.01961339  1.20139682 -0.51445049  0.87127191
  -0.84195602 -0.42934772  0.72424781  2.81590962  1.38487351  0.09679122
  -1.69863725  0.51858032 -0.89967597 -0.8061415   1.30964935  1.25655735
   1.72303295  0.13572095  0.40067232  1.50670588  0.63558042 -2.15651512
  -0.63475066  0.08975225 -0.89642376 -1.90117395 -0.88255304  1.73258018
  -0.55859691 -0.39813596 -0.01292513 -1.15821922 -1.41993654  2.64968705
  -0.05133021 -0.29966334 -0.9143604   0.23348728 -0.76690662  0.70444953
   0.04880683 -0.86054093  0.33218086 -0.94315743  1.78141439  1.72230577
   0.81991017  0.19381645  0.13632378 -0.09145033  2.54850554 -0.37821788
   0.91460961  0.28095412  0.10748758 -0.13966984  1.31017363 -0.15739512
   0.29987678 -0.07307633  1.86144507 -0.04701281  1.55473948 -0.8165288
  -1.72585511  0.00913785  0.11824295 -1.14586198 -0.44383726 -0.69709909
   0.42558798  1.81410623  0.40949112  0.84328133 -1.4845798   0.1735418
   0.85045308  0.80171931  0.31724817 -0.9030571  -0.37638131  0.75770807
   1.71149111 -0.63592589  1.29053533 -1.65990567  2.07380939 -0.27924535
  -0.48998618  1.97275066 -0.29810977  0.33688858 -0.25571889  0.82322776
   0.77036726 -0.53749245 -1.29554927 -0.23693217]]
train mean loss=69.6221488081
training perplexity=5.7004990304
saving model....
epoch: 5 / 30
ソフトバンク [[ 0.17320789  1.16710246 -1.02371418  1.20339835 -0.52124721  0.87559736
  -0.84542912 -0.42404789  0.71839458  2.8174839   1.38590753  0.09866919
  -1.70370185  0.52274376 -0.89601737 -0.79971218  1.30291271  1.26275742
   1.71934056  0.12973656  0.40449503  1.50798035  0.63169694 -2.16271186
  -0.63053483  0.09508361 -0.8959288  -1.90616548 -0.88909113  1.72522557
  -0.56315356 -0.39788869 -0.0200442  -1.15507734 -1.42519093  2.65455961
  -0.05861819 -0.29468873 -0.91157985  0.23028584 -0.76163369  0.70935458
   0.05255217 -0.86364788  0.33523884 -0.94838369  1.77632403  1.71770155
   0.81952971  0.18845879  0.13322343 -0.09182756  2.54609632 -0.38352939
   0.91314948  0.28044343  0.10224751 -0.14534982  1.31192768 -0.15980287
   0.29503068 -0.07327151  1.86301064 -0.0527068   1.54955256 -0.81381464
  -1.73150313  0.00623152  0.1176195  -1.13939011 -0.44477645 -0.69319087
   0.43205214  1.80987     0.40551934  0.84104967 -1.49076259  0.17257613
   0.8506515   0.8072778   0.31917155 -0.89983416 -0.37196043  0.75806791
   1.71364212 -0.64390963  1.29436207 -1.66692364  2.07198834 -0.28509232
  -0.48795673  1.97000337 -0.29300788  0.33150992 -0.25140676  0.82879603
   0.76266873 -0.53438282 -1.30031562 -0.24273078]]
train mean loss=67.8537609972
training perplexity=5.4539713148
saving model....
epoch: 6 / 30
ソフトバンク [[ 0.17339575  1.17004454 -1.02689683  1.20494592 -0.52665395  0.87926137
  -0.8480531  -0.41940552  0.71345842  2.81859469  1.38671541  0.10008448
  -1.70768344  0.5260725  -0.89347297 -0.7943269   1.29714     1.26808083
   1.71631002  0.12496252  0.40736884  1.50980389  0.62846822 -2.16778755
  -0.62709707  0.0995786  -0.89491898 -1.91045249 -0.8948186   1.71936452
  -0.56697983 -0.39740643 -0.02630657 -1.15271032 -1.42936754  2.65842795
  -0.06482223 -0.29044655 -0.90961349  0.22808631 -0.75705159  0.71318167
   0.05555953 -0.86623919  0.33800051 -0.95264333  1.77189016  1.71363366
   0.81886816  0.18401822  0.13074791 -0.09147444  2.54414678 -0.38765317
   0.91217351  0.28042415  0.09817263 -0.14991716  1.31239092 -0.16163474
   0.29127818 -0.07282985  1.86358678 -0.05736886  1.54533613 -0.81166452
  -1.73600328  0.00398164  0.11715581 -1.1339761  -0.44515905 -0.68962228
   0.43732795  1.80656683  0.40230933  0.83852524 -1.49585795  0.17125614
   0.85047537  0.81289321  0.32077393 -0.89694923 -0.368366    0.75866282
   1.7153368  -0.65045315  1.29736876 -1.67272174  2.07065535 -0.29012081
  -0.48669815  1.96731484 -0.28862306  0.32716197 -0.24789526  0.83331722
   0.75615966 -0.5319373  -1.30422974 -0.24734245]]
train mean loss=66.4945809882
training perplexity=5.27176132881
saving model....
epoch: 7 / 30
ソフトバンク [[  1.73420638e-01   1.17251146e+00  -1.02946746e+00   1.20618331e+00
   -5.31087220e-01   8.82445335e-01  -8.50100338e-01  -4.15185958e-01
    7.09171236e-01   2.81940508e+00   1.38731623e+00   1.01134770e-01
   -1.71094298e+00   5.28839529e-01  -8.91660333e-01  -7.89637685e-01
    1.29203999e+00   1.27261162e+00   1.71368444e+00   1.21045277e-01
    4.09631222e-01   1.51189280e+00   6.25670373e-01  -2.17207193e+00
   -6.24182940e-01   1.03495426e-01  -8.93630326e-01  -1.91422606e+00
   -8.99881661e-01   1.71448588e+00  -5.70318878e-01  -3.96836877e-01
   -3.18901539e-02  -1.15082085e+00  -1.43282890e+00   2.66164422e+00
   -7.02836066e-02  -2.86695153e-01  -9.08221185e-01   2.26551533e-01
   -7.53025353e-01   7.16298878e-01   5.80465943e-02  -8.68406892e-01
    3.40437859e-01  -9.56228256e-01   1.76790643e+00   1.70991015e+00
    8.18141937e-01   1.80250287e-01   1.28626928e-01  -9.07159597e-02
    2.54249668e+00  -3.90977502e-01   9.11492229e-01   2.80743390e-01
    9.48988497e-02  -1.53747380e-01   1.31204784e+00  -1.63105518e-01
    2.88262993e-01  -7.20239654e-02   1.86358023e+00  -6.12771101e-02
    1.54179513e+00  -8.09967816e-01  -1.73971641e+00   2.17730296e-03
    1.16783589e-01  -1.12929082e+00  -4.45231467e-01  -6.86277211e-01
    4.41792548e-01   1.80386889e+00   3.99711072e-01   8.35866988e-01
   -1.50023079e+00   1.69768989e-01   8.50109220e-01   8.18356633e-01
    3.22226942e-01  -8.94315422e-01  -3.65374446e-01   7.59337127e-01
    1.71674562e+00  -6.56005204e-01   1.29973209e+00  -1.67769039e+00
    2.06960273e+00  -2.94531584e-01  -4.85938042e-01   1.96472776e+00
   -2.84712374e-01   3.23475808e-01  -2.44930312e-01   8.37124109e-01
    7.50448585e-01  -5.29967964e-01  -1.30759537e+00  -2.51199394e-01]]
train mean loss=65.396644249
training perplexity=5.12902768548
saving model....
epoch: 8 / 30
ソフトバンク [[  1.73311308e-01   1.17459536e+00  -1.03158259e+00   1.20722842e+00
   -5.34784079e-01   8.85228813e-01  -8.51750910e-01  -4.11335349e-01
    7.05369115e-01   2.81993198e+00   1.38776755e+00   1.01884350e-01
   -1.71363902e+00   5.31164348e-01  -8.90406311e-01  -7.85483479e-01
    1.28746533e+00   1.27648365e+00   1.71139014e+00   1.17754214e-01
    4.11386490e-01   1.51406419e+00   6.23187065e-01  -2.17575574e+00
   -6.21677816e-01   1.06955871e-01  -8.92159879e-01  -1.91759443e+00
   -9.04428840e-01   1.71033370e+00  -5.73257625e-01  -3.96256775e-01
   -3.69342268e-02  -1.14928722e+00  -1.43571866e+00   2.66437197e+00
   -7.51480609e-02  -2.83313036e-01  -9.07228768e-01   2.25528866e-01
   -7.49387205e-01   7.18846381e-01   6.01732209e-02  -8.70253623e-01
    3.42606604e-01  -9.59299922e-01   1.76428378e+00   1.70645618e+00
    8.17367017e-01   1.76978454e-01   1.26721695e-01  -8.97106677e-02
    2.54106045e+00  -3.93694729e-01   9.11015987e-01   2.81222314e-01
    9.21918899e-02  -1.56997025e-01   1.31114709e+00  -1.64305493e-01
    2.85799652e-01  -7.10079446e-02   1.86320734e+00  -6.46383986e-02
    1.53877151e+00  -8.08599770e-01  -1.74281907e+00   7.13311892e-04
    1.16465546e-01  -1.12516654e+00  -4.45098639e-01  -6.83114529e-01
    4.45639163e-01   1.80164087e+00   3.97578865e-01   8.33222032e-01
   -1.50403368e+00   1.68219954e-01   8.49643111e-01   8.23589802e-01
    3.23584616e-01  -8.91877413e-01  -3.62868547e-01   7.59974539e-01
    1.71794593e+00  -6.60796165e-01   1.30169022e+00  -1.68198776e+00
    2.06872821e+00  -2.98435092e-01  -4.85526532e-01   1.96228766e+00
   -2.81185597e-01   3.20297629e-01  -2.42365465e-01   8.40370119e-01
    7.45378971e-01  -5.28324664e-01  -1.31054485e+00  -2.54453212e-01]]
train mean loss=64.4810145569
training perplexity=5.01295400915
saving model....
epoch: 9 / 30
ソフトバンク [[  1.73241004e-01   1.17635691e+00  -1.03330743e+00   1.20810235e+00
   -5.37798643e-01   8.87673318e-01  -8.53063166e-01  -4.07802016e-01
    7.01940536e-01   2.82021117e+00   1.38795018e+00   1.02437854e-01
   -1.71586525e+00   5.33106208e-01  -8.89676869e-01  -7.81780779e-01
    1.28330410e+00   1.27970064e+00   1.70933604e+00   1.15085870e-01
    4.12687033e-01   1.51628327e+00   6.20909274e-01  -2.17887688e+00
   -6.19457603e-01   1.10038646e-01  -8.90432775e-01  -1.92068326e+00
   -9.08482015e-01   1.70685995e+00  -5.75863957e-01  -3.95712525e-01
   -4.15844359e-02  -1.14802623e+00  -1.43807971e+00   2.66662574e+00
   -7.94979408e-02  -2.80213386e-01  -9.06591415e-01   2.24977911e-01
   -7.46098459e-01   7.20880330e-01   6.19148798e-02  -8.71759117e-01
    3.44451964e-01  -9.61898506e-01   1.76090741e+00   1.70328689e+00
    8.16699326e-01   1.74181625e-01   1.24993168e-01  -8.86149704e-02
    2.53976846e+00  -3.95835787e-01   9.10627007e-01   2.81810403e-01
    9.00124684e-02  -1.59759060e-01   1.30977046e+00  -1.65276125e-01
    2.83853471e-01  -6.98416233e-02   1.86246514e+00  -6.74936175e-02
    1.53613770e+00  -8.07505727e-01  -1.74534345e+00  -4.83960757e-04
    1.16096511e-01  -1.12154245e+00  -4.44867492e-01  -6.80076420e-01
    4.48929250e-01   1.79980075e+00   3.95835668e-01   8.30697417e-01
   -1.50728762e+00   1.66624084e-01   8.49205971e-01   8.28564584e-01
    3.24879378e-01  -8.89615953e-01  -3.60832930e-01   7.60607958e-01
    1.71901488e+00  -6.64926171e-01   1.30327892e+00  -1.68573618e+00
    2.06791973e+00  -3.01906407e-01  -4.85386819e-01   1.96010137e+00
   -2.77899832e-01   3.17598283e-01  -2.40119651e-01   8.43146086e-01
    7.40876377e-01  -5.26968062e-01  -1.31312513e+00  -2.57166445e-01]]
train mean loss=63.7013715744
training perplexity=4.91619220784
saving model....
epoch: 10 / 30
ソフトバンク [[  1.73135057e-01   1.17788374e+00  -1.03478885e+00   1.20883679e+00
   -5.40397644e-01   8.89876962e-01  -8.54183793e-01  -4.04515564e-01
    6.98805153e-01   2.82033038e+00   1.38802314e+00   1.02856219e-01
   -1.71781027e+00   5.34817636e-01  -8.89234781e-01  -7.78384447e-01
    1.27945828e+00   1.28251505e+00   1.70749128e+00   1.12798490e-01
    4.13714081e-01   1.51845872e+00   6.18840337e-01  -2.18165255e+00
   -6.17460907e-01   1.12845846e-01  -8.88660371e-01  -1.92354751e+00
   -9.12195861e-01   1.70379841e+00  -5.78245401e-01  -3.95258993e-01
   -4.59218435e-02  -1.14693189e+00  -1.44013011e+00   2.66862059e+00
   -8.35087150e-02  -2.77311593e-01  -9.06181216e-01   2.24712819e-01
   -7.43105590e-01   7.22617507e-01   6.34272620e-02  -8.73024702e-01
    3.46039921e-01  -9.64206874e-01   1.75776231e+00   1.70034194e+00
    8.16092908e-01   1.71710476e-01   1.23397380e-01  -8.74747038e-02
    2.53856301e+00  -3.97632480e-01   9.10301924e-01   2.82496601e-01
    8.81731957e-02  -1.62200660e-01   1.30820262e+00  -1.66076154e-01
    2.82216817e-01  -6.85859472e-02   1.86155856e+00  -7.00672492e-02
    1.53374255e+00  -8.06589007e-01  -1.74751389e+00  -1.49389484e-03
    1.15718834e-01  -1.11823916e+00  -4.44591045e-01  -6.77203417e-01
    4.51847851e-01   1.79820120e+00   3.94336611e-01   8.28217685e-01
   -1.51018929e+00   1.65065855e-01   8.48754823e-01   8.33287358e-01
    3.26095372e-01  -8.87472808e-01  -3.59102577e-01   7.61188447e-01
    1.71997213e+00  -6.68575764e-01   1.30467594e+00  -1.68914330e+00
    2.06717372e+00  -3.05030793e-01  -4.85419661e-01   1.95802450e+00
   -2.74792999e-01   3.15185875e-01  -2.38108769e-01   8.45625699e-01
    7.36761272e-01  -5.25820553e-01  -1.31544530e+00  -2.59579957e-01]]
train mean loss=63.0242273385
training perplexity=4.83366840469
saving model....
epoch: 11 / 30
ソフトバンク [[  1.73116148e-01   1.17924035e+00  -1.03603673e+00   1.20946789e+00
   -5.42569935e-01   8.91843617e-01  -8.55108500e-01  -4.01392579e-01
    6.95901334e-01   2.82030916e+00   1.38794768e+00   1.03127643e-01
   -1.71950328e+00   5.36305845e-01  -8.89067709e-01  -7.75265515e-01
    1.27588499e+00   1.28490734e+00   1.70577478e+00   1.10842064e-01
    4.14507389e-01   1.52052104e+00   6.16906583e-01  -2.18409038e+00
   -6.15636170e-01   1.15427934e-01  -8.86791050e-01  -1.92624760e+00
   -9.15624022e-01   1.70112538e+00  -5.80440283e-01  -3.94861639e-01
   -4.99794595e-02  -1.14598250e+00  -1.44188154e+00   2.67031860e+00
   -8.72215480e-02  -2.74592519e-01  -9.05974329e-01   2.24684939e-01
   -7.40389884e-01   7.24080920e-01   6.47180974e-02  -8.74095976e-01
    3.47400129e-01  -9.66253340e-01   1.75479794e+00   1.69758487e+00
    8.15586448e-01   1.69508398e-01   1.21868186e-01  -8.63296241e-02
    2.53748226e+00  -3.99124622e-01   9.10013080e-01   2.83208102e-01
    8.66513252e-02  -1.64348468e-01   1.30644739e+00  -1.66775465e-01
    2.80853033e-01  -6.72698915e-02   1.86057615e+00  -7.23466575e-02
    1.53157711e+00  -8.05845201e-01  -1.74935877e+00  -2.34211562e-03
    1.15268879e-01  -1.11524379e+00  -4.44253117e-01  -6.74424171e-01
    4.54441756e-01   1.79681993e+00   3.93096775e-01   8.25827062e-01
   -1.51276851e+00   1.63523570e-01   8.48369002e-01   8.37747157e-01
    3.27280164e-01  -8.85449171e-01  -3.57668757e-01   7.61741161e-01
    1.72087002e+00  -6.71832144e-01   1.30587041e+00  -1.69221425e+00
    2.06647706e+00  -3.07886392e-01  -4.85575050e-01   1.95613647e+00
   -2.71815896e-01   3.13051671e-01  -2.36298874e-01   8.47827494e-01
    7.33001292e-01  -5.24840117e-01  -1.31756914e+00  -2.61719912e-01]]
train mean loss=62.426081919
training perplexity=4.76192523676
saving model....
epoch: 12 / 30
ソフトバンク [[ 0.17314382  1.18043208 -1.03708565  1.20999742 -0.54438448  0.89364988
  -0.85587567 -0.39846122  0.69322753  2.82012081  1.38775289  0.10332094
  -1.72098029  0.53760749 -0.88913769 -0.77238607  1.27256441  1.28693986
   1.70422029  0.10921828  0.41505489  1.52246904  0.61510313 -2.18623209
  -0.61395943  0.11778703 -0.884839   -1.92880917 -0.9188568   1.69877076
  -0.58246607 -0.39459246 -0.05381892 -1.14518356 -1.4433434   2.67179012
  -0.09066748 -0.27202007 -0.90592635  0.22488399 -0.73788947  0.72529715
   0.0657705  -0.87503374  0.34854406 -0.96805859  1.75200367  1.69506025
   0.81522715  0.16758561  0.1204221  -0.08520424  2.53647184 -0.40032434
   0.90975547  0.28398359  0.08542094 -0.16624895  1.30453765 -0.16733228
   0.27973124 -0.06587999  1.85947204 -0.07440668  1.5295893  -0.80528694
  -1.75089264 -0.00305455  0.11478753 -1.11250162 -0.44390801 -0.67175901
   0.45672902  1.79566228  0.39201626  0.82351291 -1.51503849  0.16201513
   0.84801662  0.84200698  0.32840067 -0.88354051 -0.3565135   0.76225764
   1.72171998 -0.67472011  1.30688453 -1.69501853  2.06580591 -0.31051323
  -0.48587072  1.95438457 -0.26896021  0.31115413 -0.23467179  0.84979838
   0.72957045 -0.52402556 -1.31949639 -0.26359695]]
train mean loss=61.8988105174
training perplexity=4.69956646483
saving model....
epoch: 13 / 30
ソフトバンク [[ 0.17316288  1.18150008 -1.03798568  1.21051073 -0.54593438  0.89526808
  -0.85653365 -0.39570016  0.69074535  2.8198719   1.38750899  0.10342226
  -1.72228944  0.53875917 -0.88935643 -0.76972538  1.26946354  1.28865314
   1.70278823  0.10782371  0.4154405   1.52427936  0.61341339 -2.18815041
  -0.61242247  0.11996708 -0.88294536 -1.93122828 -0.9218486   1.69666469
  -0.58433652 -0.39439705 -0.05742961 -1.14447784 -1.44463205  2.67308235
  -0.09384304 -0.26958805 -0.90597337  0.22520693 -0.73556036  0.72631943
   0.06669721 -0.8757847   0.34959573 -0.96968102  1.74939489  1.69269586
   0.81488645  0.16585416  0.11905457 -0.08406945  2.53551507 -0.40133053
   0.90952325  0.28476971  0.08436775 -0.16793725  1.30262816 -0.16778956
   0.27877662 -0.06447556  1.85839462 -0.07626365  1.52777851 -0.80478024
  -1.7522043  -0.00363295  0.11430496 -1.10996759 -0.44355905 -0.66919464
   0.45879704  1.79462576  0.39109975  0.82130587 -1.51708007  0.16054125
   0.84768701  0.84602576  0.32945779 -0.88178009 -0.35556415  0.76272184
   1.7224586  -0.67730999  1.30779195 -1.69758105  2.06515551 -0.312924
  -0.48626125  1.95273972 -0.2662296   0.3094635  -0.23319575  0.85156995
   0.72639865 -0.5233447  -1.32127559 -0.26527587]]
train mean loss=61.422296366
training perplexity=4.64391336845
saving model....
epoch: 14 / 30
ソフトバンク [[ 0.17322715  1.18248832 -1.03876972  1.2109257  -0.54728216  0.89674866
  -0.85708654 -0.3930777   0.68839812  2.8195796   1.3871665   0.10343499
  -1.72342849  0.53979707 -0.88970286 -0.76722199  1.2665273   1.29014885
   1.70145333  0.10654948  0.41572452  1.52595973  0.61185026 -2.1898818
  -0.6109671   0.12203353 -0.88102883 -1.93349886 -0.92467105  1.69479716
  -0.58608311 -0.39423734 -0.06082051 -1.14384949 -1.4457159   2.67424202
  -0.09682449 -0.26728138 -0.90614408  0.22564796 -0.73340881  0.72721374
   0.06749834 -0.8765108   0.35046145 -0.97111857  1.74690044  1.69045699
   0.81462723  0.16431747  0.11774891 -0.08300124  2.53466225 -0.40216032
   0.90930682  0.2855359   0.08347442 -0.16949283  1.300699   -0.16820174
   0.27797723 -0.0631225   1.85729051 -0.07793634  1.52612829 -0.804398
  -1.7533406  -0.00415634  0.11379378 -1.10762191 -0.4432061  -0.66676527
   0.46066761  1.7937299   0.39030799  0.81923479 -1.51895869  0.15919054
   0.84740973  0.84982431  0.3304376  -0.88010353 -0.35477537  0.76304281
   1.72316825 -0.67966998  1.30860078 -1.69998181  2.06459904 -0.31515241
  -0.48671812  1.95120335 -0.26363155  0.30792373 -0.23181328  0.85322148
   0.72343993 -0.52275556 -1.32296205 -0.2668049 ]]
train mean loss=60.9905445099
training perplexity=4.59405746432
saving model....
epoch: 15 / 30
ソフトバンク [[ 0.17329581  1.18336296 -1.0394243   1.21137571 -0.54844481  0.89808077
  -0.85754901 -0.39056283  0.68620539  2.81926966  1.3868469   0.10336828
  -1.72443509  0.54070318 -0.89014983 -0.76489729  1.26376724  1.29142368
   1.70021784  0.10543403  0.41592169  1.52750862  0.61037636 -2.19146013
  -0.60962373  0.12395707 -0.87918574 -1.93566048 -0.92732495  1.69310987
  -0.58770245 -0.39410338 -0.0640312  -1.1433146  -1.44669199  2.67526507
  -0.09964423 -0.26508743 -0.9063707   0.22618186 -0.73139822  0.72797006
   0.06819699 -0.87709516  0.35128045 -0.97241879  1.74455559  1.68833435
   0.81439579  0.16288884  0.11649038 -0.0819206   2.53386235 -0.40288454
   0.90913099  0.28632262  0.08267675 -0.17087944  1.29877222 -0.1685266
   0.27727878 -0.06171963  1.8562566  -0.07948188  1.5246079  -0.80405134
  -1.75432277 -0.00455147  0.11329658 -1.10542226 -0.44282281 -0.66436827
   0.46239078  1.79292309  0.38962042  0.8172152  -1.52066743  0.15782209
   0.84714133  0.85347193  0.33138752 -0.87857044 -0.35414737  0.76333874
   1.72374666 -0.68180817  1.30932593 -1.70217752  2.06407595 -0.31724265
  -0.4872427   1.94972026 -0.26116392  0.30652544 -0.23057728  0.85470343
   0.72067469 -0.52227253 -1.3245182  -0.26818323]]
train mean loss=60.5963276563
training perplexity=4.54900347007
saving model....
epoch: 16 / 30
ソフトバンク [[ 0.17338718  1.18418825 -1.03998721  1.21178067 -0.54945272  0.89931685
  -0.85793626 -0.3881436   0.68412358  2.81892538  1.38645828  0.10326061
  -1.72535419  0.54153621 -0.89065605 -0.76270914  1.26114905  1.29254639
   1.69906962  0.10445794  0.41604763  1.52890873  0.60897213 -2.19289017
  -0.60836482  0.12576371 -0.87737894 -1.93773723 -0.92984957  1.69156146
  -0.58924109 -0.3940112  -0.0670684  -1.14284277 -1.44755685  2.67616987
  -0.10233286 -0.26300201 -0.90665478  0.22677277 -0.72954243  0.72864246
   0.06879303 -0.87764966  0.35195839 -0.97362167  1.74233878  1.68636215
   0.81423712  0.16158886  0.11526314 -0.08091035  2.5331192  -0.40350661
   0.90894616  0.28709048  0.08200575 -0.17215379  1.29687774 -0.16880926
   0.2766754  -0.06032572  1.85525453 -0.08094519  1.52319872 -0.80379152
  -1.75518346 -0.00488159  0.11278541 -1.10335231 -0.44244218 -0.66208255
   0.46396556  1.79219973  0.38902754  0.81523412 -1.52223587  0.15650393
   0.84692556  0.85694176  0.33227864 -0.87711358 -0.35365066  0.76363271
   1.72430038 -0.68377125  1.30996919 -1.70423889  2.06358337 -0.31919608
  -0.48780355  1.94832504 -0.25879475  0.30523807 -0.22943556  0.85608029
   0.71807688 -0.52188116 -1.32598603 -0.26947203]]
train mean loss=60.2338160161
training perplexity=4.50796305359
saving model....
epoch: 17 / 30
ソフトバンク [[ 0.17347877  1.18493736 -1.04048014  1.21220601 -0.55034488  0.90044045
  -0.85829574 -0.38581908  0.68215519  2.81858468  1.38607478  0.10309346
  -1.72616804  0.54228348 -0.89123172 -0.7606557   1.25864732  1.29348242
   1.69799566  0.10356571  0.41609487  1.53023303  0.60765225 -2.19422722
  -0.60716271  0.12748721 -0.87562621 -1.93971634 -0.9322325   1.69013762
  -0.59068525 -0.39395726 -0.06998202 -1.14241111 -1.44833875  2.67700553
  -0.10487508 -0.26099446 -0.90697289  0.22741723 -0.72776884  0.72922313
   0.06934019 -0.87809956  0.35260376 -0.97471714  1.74023235  1.68444359
   0.81409883  0.16038765  0.1140696  -0.07990751  2.5324266  -0.40404239
   0.90878499  0.28786635  0.08139531 -0.17332773  1.29501081 -0.16904509
   0.27614793 -0.05894469  1.8543129  -0.08226606  1.52188933 -0.80353487
  -1.75594306 -0.00514995  0.11228074 -1.10138488 -0.4420743  -0.65986103
   0.46544144  1.79154015  0.38850355  0.81334281 -1.52369082  0.15521969
   0.84670877  0.86027956  0.33313981 -0.87576306 -0.35323986  0.76382077
   1.72476506 -0.68557024  1.3105799  -1.70616591  2.06311965 -0.32103601
  -0.48841357  1.94698429 -0.25651169  0.30405247 -0.22836445  0.85735935
   0.71561974 -0.52155417 -1.32738519 -0.27067921]]
train mean loss=59.9005292838
training perplexity=4.47055799573
saving model....
epoch: 18 / 30
ソフトバンク [[ 0.17358603  1.18561316 -1.0408988   1.21261406 -0.55112815  0.90149206
  -0.85857731 -0.38360316  0.68026674  2.81825948  1.38565254  0.10288089
  -1.72691655  0.54296374 -0.89185888 -0.75869483  1.25626016  1.29431188
   1.69699407  0.10276879  0.41613802  1.53145158  0.60639477 -2.19545531
  -0.60603386  0.12911716 -0.87389964 -1.94162917 -0.93453938  1.68882751
  -0.5920434  -0.39393371 -0.07277108 -1.14203954 -1.44902444  2.67774487
  -0.10730862 -0.25906602 -0.9073633   0.2281349  -0.7261135   0.72973251
   0.06981292 -0.87854093  0.35316703 -0.97572035  1.73820603  1.68264318
   0.81399232  0.15929     0.11292819 -0.07895751  2.53176856 -0.40448403
   0.90861273  0.28859672  0.08087281 -0.17440914  1.29317057 -0.16922654
   0.27570084 -0.05756143  1.85336375 -0.08353598  1.52066386 -0.80335891
  -1.75659251 -0.00536412  0.11175288 -1.0995307  -0.44170073 -0.65769726
   0.46679875  1.79094648  0.38802719  0.81149763 -1.52504158  0.15396507
   0.84652865  0.86348784  0.33393717 -0.87446356 -0.35293493  0.76403403
   1.72519875 -0.68724263  1.31114352 -1.70800686  2.06267858 -0.32272691
  -0.48905736  1.94572735 -0.25430796  0.30295351 -0.22737609  0.85856527
   0.71328998 -0.52129245 -1.32870662 -0.27179334]]
train mean loss=59.5887134879
training perplexity=4.43584371231
saving model....
epoch: 19 / 30
ソフトバンク [[ 0.17368668  1.18625891 -1.04126132  1.21302783 -0.5518409   0.902448
  -0.85882616 -0.38144439  0.6784572   2.81794882  1.3852545   0.10260788
  -1.72757757  0.54359382 -0.89249969 -0.75685054  1.25397491  1.29505491
   1.69604278  0.10203382  0.41617283  1.53258991  0.60520625 -2.19661713
  -0.60495943  0.13067186 -0.87227374 -1.9434371  -0.93670458  1.68760955
  -0.59333539 -0.39390376 -0.07539735 -1.14171481 -1.44968176  2.67842937
  -0.10963908 -0.2572397  -0.90775561  0.22884151 -0.72455442  0.73019689
   0.07025378 -0.87891746  0.35370687 -0.97665238  1.73629558  1.68089724
   0.81391937  0.15823264  0.11180547 -0.07803151  2.53119349 -0.40491024
   0.90846926  0.28934199  0.08037603 -0.17542844  1.29141665 -0.16941333
   0.27528697 -0.05620134  1.85252547 -0.08469389  1.5195533  -0.80318141
  -1.75720322 -0.00553051  0.11125561 -1.09776092 -0.44130686 -0.65559524
   0.46809569  1.79040444  0.3876439   0.80971879 -1.52633226  0.15275308
   0.84637153  0.86654866  0.33471444 -0.8732785  -0.35267952  0.76419169
   1.72556078 -0.68878627  1.3116715  -1.70971572  2.0622921  -0.32435936
  -0.48971671  1.94450068 -0.25223312  0.3019172  -0.22644901  0.85968024
   0.71106654 -0.52107292 -1.32998288 -0.27285725]]
train mean loss=59.2994419752
training perplexity=4.40388034723
saving model....
epoch: 20 / 30
ソフトバンク [[ 0.17375289  1.18686843 -1.04156911  1.21342361 -0.55251962  0.90334088
  -0.85903776 -0.37936214  0.67673314  2.81766224  1.38485169  0.10232271
  -1.72817945  0.54418659 -0.89313936 -0.75510007  1.2518034   1.29574597
   1.69515908  0.1013309   0.41619971  1.53364396  0.60409057 -2.19772911
  -0.60395926  0.1321454  -0.87073481 -1.94515526 -0.9388088   1.68644118
  -0.59456462 -0.39386174 -0.07786864 -1.14143729 -1.45029593  2.6790719
  -0.1118762  -0.25551161 -0.90815246  0.22954847 -0.72311747  0.73064524
   0.07064969 -0.87930572  0.35420766 -0.97751713  1.7345041   1.67922032
   0.81382096  0.15724924  0.11072864 -0.07713153  2.53066039 -0.40530547
   0.90835196  0.29007298  0.07990319 -0.17639391  1.28973544 -0.16956106
   0.27491331 -0.05487164  1.85174322 -0.08582927  1.5185281  -0.80305028
  -1.7577492  -0.00565048  0.11079083 -1.09606862 -0.44090134 -0.65361196
   0.46932185  1.78990376  0.38731444  0.8079868  -1.52756548  0.15162522
   0.84620547  0.86949605  0.33540469 -0.87215418 -0.35247788  0.76425809
   1.72585845 -0.69026792  1.3121773  -1.7113452   2.06198931 -0.32590804
  -0.4904041   1.94329393 -0.25031075  0.30093342 -0.22557469  0.86074054
   0.70893013 -0.52090138 -1.33121681 -0.27386868]]
train mean loss=59.0295429284
training perplexity=4.37426529533
saving model....
epoch: 21 / 30
ソフトバンク [[ 0.17386691  1.18742931 -1.04181612  1.21380115 -0.55307949  0.90418792
  -0.85920209 -0.37734109  0.6750688   2.8173275   1.38437939  0.10202932
  -1.72874928  0.54471755 -0.89385641 -0.75342202  1.24969578  1.29629993
   1.69431949  0.10072153  0.41615611  1.53460705  0.60302103 -2.19874001
  -0.60299134  0.13356327 -0.86916685 -1.94684827 -0.94084167  1.68537104
  -0.59572977 -0.39389461 -0.08030898 -1.14120173 -1.45081353  2.67964649
  -0.11402983 -0.25381774 -0.9086042   0.23031314 -0.72174025  0.73101461
   0.07097644 -0.87966102  0.35464486 -0.97831076  1.73275149  1.67764068
   0.81379896  0.15637153  0.10968301 -0.07626755  2.53013921 -0.4056026
   0.90821809  0.2907964   0.07951811 -0.17728847  1.28801942 -0.16966185
   0.27460951 -0.05351811  1.85095751 -0.08690014  1.51754963 -0.80298144
  -1.75820303 -0.00572812  0.11027617 -1.09444833 -0.44051355 -0.65166086
   0.4704403   1.78946161  0.38699117  0.80631238 -1.52868986  0.15051438
   0.84607548  0.87238955  0.3360815  -0.87107795 -0.35238215  0.76433527
   1.72616708 -0.69162893  1.31264079 -1.71291196  2.06165862 -0.32738447
  -0.49112499  1.94218862 -0.24840029  0.30004424 -0.22477947  0.86174202
   0.70690084 -0.52079791 -1.33239162 -0.27480453]]
train mean loss=58.7750116566
training perplexity=4.34651898503
saving model....
epoch: 22 / 30
ソフトバンク [[ 0.17394948  1.18799627 -1.0420388   1.21417284 -0.55361331  0.90498632
  -0.85936922 -0.37536857  0.67345381  2.81702995  1.38395298  0.10169835
  -1.72927952  0.54523796 -0.89453411 -0.75180912  1.24765718  1.2968446
   1.693501    0.10011921  0.41612235  1.53550875  0.60198438 -2.19972301
  -0.60205734  0.1349307  -0.86768746 -1.9484762  -0.94280732  1.68432951
  -0.59687948 -0.39390478 -0.0826303  -1.14098263 -1.45133698  2.68018746
  -0.11613556 -0.25219467 -0.90904737  0.23104739 -0.72043341  0.73138458
   0.07129674 -0.88000321  0.35505444 -0.97907835  1.7310847   1.67609155
   0.81376493  0.15549818  0.10862526 -0.0754177   2.52965355 -0.40592486
   0.90810102  0.29149896  0.07914292 -0.17814191  1.28639328 -0.16976361
   0.27430087 -0.05220429  1.85027397 -0.08793874  1.51663542 -0.80288631
  -1.75864995 -0.00578436  0.1098022  -1.09286928 -0.44012001 -0.64976084
   0.47153929  1.78902447  0.38672838  0.80464667 -1.52979505  0.1494125
   0.84594542  0.87518764  0.33673641 -0.87006021 -0.35230249  0.76437366
   1.72641945 -0.6929298   1.31309283 -1.71440113  2.06140423 -0.3288188
  -0.49184409  1.94106293 -0.24659275  0.29917482 -0.22401138  0.8627013
   0.70491958 -0.52071196 -1.33354199 -0.27573186]]
train mean loss=58.5343913814
training perplexity=4.32045095498
saving model....
epoch: 23 / 30
ソフトバンク [[ 0.17400287  1.18850029 -1.04222131  1.21456575 -0.55412918  0.90572041
  -0.85949904 -0.3734591   0.6718995   2.8167727   1.38353968  0.10134333
  -1.72974205  0.54570854 -0.8952269  -0.75027257  1.24568856  1.29732823
   1.69273829  0.09955286  0.41609976  1.53636026  0.60100389 -2.20066762
  -0.60117364  0.13624702 -0.86628044 -1.9500258  -0.94467789  1.68335199
  -0.5979448  -0.39391345 -0.08484366 -1.14079463 -1.45182657  2.68070245
  -0.11814912 -0.25063625 -0.90949678  0.23178647 -0.71919674  0.73172021
   0.07160629 -0.88029695  0.3554602  -0.97978276  1.72949588  1.67457306
   0.81371975  0.15467875  0.10762805 -0.07458882  2.52920914 -0.40621215
   0.90799332  0.29215336  0.07875787 -0.17895816  1.28482878 -0.16984397
   0.2740283  -0.05090519  1.84961677 -0.08890925  1.5158025  -0.80280024
  -1.75906193 -0.00579798  0.10935292 -1.09136367 -0.43971619 -0.64790893
   0.47258502  1.78861618  0.38649252  0.80307424 -1.53085577  0.14836422
   0.8458057   0.87788749  0.33734831 -0.86912054 -0.35225126  0.76435751
   1.72661543 -0.69415331  1.31355774 -1.71582568  2.06117201 -0.33016378
  -0.49257573  1.93998921 -0.24488568  0.29835302 -0.2232742   0.86361229
   0.70303077 -0.52065992 -1.33465981 -0.27661008]]
train mean loss=58.3094880785
training perplexity=4.29622702707
saving model....
epoch: 24 / 30
ソフトバンク [[ 0.17406733  1.18897629 -1.0423553   1.21496975 -0.55459112  0.90641379
  -0.85961491 -0.37159631  0.67040247  2.81653619  1.3831284   0.10097639
  -1.73016834  0.54613745 -0.89594018 -0.74880463  1.24379313  1.29773831
   1.69200969  0.0990359   0.41606712  1.53716302  0.60007215 -2.20155978
  -0.60033041  0.13750808 -0.864914   -1.95153201 -0.94650155  1.68242264
  -0.5989641  -0.39391837 -0.0869886  -1.14063847 -1.45228755  2.68117881
  -0.12010589 -0.24912655 -0.90995198  0.23254704 -0.71803033  0.73202443
   0.07188447 -0.88058889  0.35584462 -0.98044622  1.72797108  1.67311132
   0.81370699  0.15389405  0.10664309 -0.07378116  2.52878308 -0.40647814
   0.90789366  0.2927992   0.07839998 -0.17971332  1.28327549 -0.16989365
   0.27378374 -0.04959899  1.84900081 -0.08984703  1.5150162  -0.80274719
  -1.75942838 -0.00577037  0.10890786 -1.08990705 -0.43931437 -0.64609379
   0.47357982  1.7882359   0.3862879   0.80150187 -1.53186882  0.1473158
   0.84568202  0.88054287  0.33793366 -0.86824203 -0.35225564  0.76435965
   1.72677588 -0.69529736  1.31399429 -1.71717811  2.06095314 -0.33146206
  -0.49333072  1.9389348  -0.24324092  0.29757005 -0.22260065  0.86447018
   0.70120478 -0.52064693 -1.3357321  -0.27743781]]
train mean loss=58.094578089
training perplexity=4.27320637193
saving model....
